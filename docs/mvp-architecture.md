# 인용형 CAG 챗봇 MVP 아키텍처 제안

본 문서는 선거법 사례집을 기반으로 하는 **인용형 Context-Augmented Generation(CAG) 챗봇**의 최소 기능 제품(MVP)을 빠르게 구현하기 위한 간소화된 구조를 설명합니다. 목표는 복잡한 오케스트레이션 프레임워크 없이도 신뢰할 수 있는 답변과 출처 인용을 제공하는 투명한 파이프라인을 확보하는 것입니다.

---

## 1. 설계 목표

- **핵심 기능 집중**: 문서 인게스트 → 검색 → 답변 생성의 세 단계만으로 MVP 완성
- **투명성과 디버깅 용이성**: LangChain 등 중간 추상화 없이 각 단계를 명시적으로 구현
- **인용 기반 응답**: 답변과 함께 근거가 되는 문서 출처를 명확하게 표기
- **CLI 우선 구현**: 서버나 UI 구성 없이 터미널에서 질문-응답을 검증할 수 있도록 설계

---

## 2. 전체 파이프라인 요약

```
사용자 질문 → 컨텍스트 검색 → Gemini 호출 → 인용 포함 응답 출력
                    ↑
            Firecrawl 인게스트 & 청크 인덱스
```

1. **지식 수집**: Firecrawl API로 지정된 URL/PDF를 Markdown 텍스트로 인게스트
2. **전처리 & 인덱싱**: Markdown을 일정 토큰/문단 단위로 청크 분할 후 검색 인덱스를 생성
3. **질의 처리**: CLI에서 질문 입력 → 질의와 유사한 청크 상위 N개 검색
4. **답변 생성**: 검색된 청크와 질문을 조합한 프롬프트를 Gemini에 전달하여 인용형 응답 생성

---

## 3. 핵심 컴포넌트 설계

| 컴포넌트 | 책임 | 구현 시 고려 사항 |
| --- | --- | --- |
| **Ingestor (Firecrawl 클라이언트)** | 지정된 URL, PDF를 Markdown으로 수집 | `scripts/`에 1회성 실행 스크립트로 구현. API 키/요청 한도 관리. |
| **Chunker** | Markdown을 일정 크기의 청크로 분할하고 메타데이터 부여 | 파일명, 헤더 정보, 페이지 번호 등을 출처 ID로 저장. |
| **Indexer/검색기** | 청크 인덱싱 및 질의-청크 매칭 | MVP 단계에서는 키워드 TF-IDF 또는 소규모 임베딩(Sentence Transformers). 메모리 내 벡터 목록으로 유지. |
| **Prompt Builder** | 검색 결과를 근거와 함께 프롬프트 문자열로 조립 | `[출처ID]` 태그 포함, 토큰 한도 고려, 질문과 지시문 명확화. |
| **Gemini Client** | 프롬프트를 Gemini(Gemini 2.5 Pro) API로 전송 | 스트리밍 미사용 가정. 응답에서 citation 태그 추출. |
| **CLI Runner** | 터미널 I/O 처리, 세션별 반복 질문 지원 | 초기 기동 시 인덱스 로드, 예외 처리 및 로깅 제공. |

---

## 4. 데이터 흐름과 저장소

1. **Raw Markdown 저장**: `data/ingested/` (예: `YYYYMMDD-source.md`)
2. **청크 메타데이터**: `data/chunks.json`
   - `id`: 출처 태그(예: `doc-001-chunk-05`)
   - `source`: 파일명 또는 URL
   - `content`: 청크 텍스트
   - `metadata`: 카테고리, 키워드, 페이지 등
3. **인덱스 캐시(선택)**: 초기화 비용을 줄이기 위해 `scripts/initCache.ts` 활용 가능
4. **실행 시 메모리 로드**: `src/chunkSearch.ts`를 확장하여 메모리에 청크와 인덱스 로드

---

## 5. 검색 전략

### 5.1 키워드 기반 (기본)
- 구현 난이도가 낮고 종속성이 적음
- 질의 토큰에 대한 단순 TF-IDF/가중치 계산 후 상위 K개 청크 반환
- 빠른 MVP 검증에 적합하나 동의어/의미 기반 검색에는 취약

### 5.2 임베딩 기반 (선택)
- `sentence-transformers/all-MiniLM-L6-v2`와 같은 경량 모델 사용
- 질의와 청크를 벡터로 변환 후 코사인 유사도 기반 상위 K개 청크 선택
- 청크 수가 적거나 메모리 내 연산이 가능한 범위에서 벡터 DB 없이도 동작
- 향후 대규모 확장을 위해 Pinecone 등 외부 벡터 스토리지로 대체 가능

두 전략은 인터페이스(`search(query, k)`)를 공유하도록 설계하여 손쉽게 교체할 수 있게 합니다.

---

## 6. Gemini 프롬프트 구성 규칙

```
[자료1|출처설명]
<청크 텍스트 1>

[자료2|출처설명]
<청크 텍스트 2>
...

사용자 질문: <사용자 입력>
지침:
- 위 자료에서만 근거를 찾아 답변합니다.
- 각 문장 끝에는 근거가 된 자료 태그([자료1])를 붙입니다.
- 답변을 한국어로 작성합니다.
```

- 컨텍스트 순서는 관련도 높은 청크부터 배치
- 필요 시 중복된 출처를 통합하여 토큰 절약
- Gemini 응답에서 `[자료X]` 패턴을 파싱하여 UI에 인용으로 표기

---

## 7. CLI 실행 흐름

1. `npm run ingest` (예: `scripts/firecrawlIngest.ts`)로 초기 데이터 수집
2. `npm run index` 또는 챗봇 실행 시 자동 인덱싱
3. `npm run cli` → 사용자 질문 입력
4. 검색 결과 및 Gemini 응답 표시, 출처 태그 포함

> CLI MVP에서 충분히 검증된 이후 웹 서버(`src/index.ts`)와 연동하여 동일한 검색·응답 모듈을 재사용할 수 있습니다.

---

## 8. 확장 로드맵

1. **검색 고도화**: 문서량 증가 시 벡터 DB 도입, 카테고리 기반 가중치, BM25 등 적용
2. **응답 품질 개선**: 장문 질문 대비 요약 단계 추가, 답변 후 검증 루틴 도입
3. **UI 확장**: 웹/모바일 인터페이스 연결, 세션 관리 및 사용자 피드백 수집
4. **실시간 업데이트**: Firecrawl로 최신 자료를 주기적으로 수집하는 배치 파이프라인 구축

---

## 9. 성공 지표 (MVP 검증)

- **정확도**: 내부 벤치마크 질문에 대해 최소 80% 이상 정확한 출처 기반 응답 달성
- **응답 속도**: 질문 입력 후 5초 이내 초기 응답 (Gemini API 지연 제외)
- **운영 편의성**: 신규 문서 추가 시 스크립트 1회 실행만으로 인덱스 재구성

---

## 10. 참고 및 의존 서비스

- **Firecrawl**: https://docs.firecrawl.dev
- **Google Gemini API**: https://ai.google.dev
- **Sentence Transformers**(선택): https://www.sbert.net

본 구조는 현 레포지토리의 `data/`·`scripts/`·`src/` 디렉터리와 자연스럽게 연계되어, 복잡한 프레임워크에 의존하지 않고도 인용 중심 CAG 챗봇 MVP를 신속하게 구축할 수 있도록 설계되었습니다.
